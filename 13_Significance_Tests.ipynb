{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Significance Tests\n",
        "\n",
        "In the world of statistics, we often use parametric methods, which assume that our data samples follow a Gaussian distribution.\n",
        "- This is particularly important in applied machine learning when we need to compare data samples, especially to evaluate whether one technique performs better than another on one or more datasets.\n",
        "\n",
        "- To address this question and make sense of the results, we employ parametric hypothesis testing methods such as the Student's t-test and ANOVA (Analysis of Variance).\n",
        "\n",
        "By the end of this tutorial, you'll have a clear understanding of:\n",
        "\n",
        "- The Student's t-test: Used to quantify the difference between the means of two independent data samples.\n",
        "\n",
        "- The paired Student's t-test: Applied when quantifying the difference between the means of two dependent data samples.\n",
        "\n",
        "- ANOVA and repeated measures ANOVA: Useful for assessing the similarity or difference between the means of two or more data samples.\n",
        "\n",
        "These significance tests are valuable tools for drawing meaningful conclusions from your data comparisons.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0XB2H874ahsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parametric Statistical Significance Tests\n",
        "\n",
        "- Parametric statistical tests make assumptions about data samples, typically assuming they follow a Gaussian distribution.\n",
        "  - Because many real-world datasets do approximate this distribution, parametric methods are widely used.\n",
        "  - These tests help answer a common question: Do two or more data samples share the same underlying distribution?\n",
        "\n",
        "- Parametric statistical significance tests work on the premise that the data is derived from the same Gaussian distribution, meaning they have the same mean and standard deviation – the defining characteristics of this distribution.\n",
        "\n",
        "- In general, each test computes a test statistic, which requires some understanding of statistics and knowledge of the specific test being used.\n",
        "  - These tests also provide a p-value, which plays a vital role in interpretation.\n",
        "  - Think of the p-value as the likelihood of observing the two data samples under the assumption (null hypothesis) that they were drawn from populations with the same distribution.\n",
        "\n",
        "- The p-value is assessed in the context of a chosen significance level, often referred to as alpha, commonly set at 5% (or 0.05). Here's how to interpret it:\n",
        "\n",
        "  - If p-value ≤ alpha, it's a significant result, and you reject the null hypothesis (H0). This suggests that the data samples probably come from different distributions.\n",
        "\n",
        "  - If p-value > alpha, it's not a significant result, and you fail to reject the null hypothesis (H0). In this case, it indicates that the data samples are likely drawn from populations with similar distributions.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HRp7Q0pZaprs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Data\n",
        "\n",
        "Before we delve into specific parametric significance tests, let's start by defining a test dataset to illustrate each test.\n",
        "\n",
        "- We'll create two samples, each drawn from different distributions.\n",
        "- Both samples will be generated from Gaussian distributions using the NumPy function `randn()`.\n",
        "- Each sample will consist of 100 Gaussian random numbers with a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "- We'll modify these samples as follows:\n",
        "  - Observations in the first sample will be adjusted to have a mean of 50 and a standard deviation of 5.\n",
        "  - Observations in the second sample will be adjusted to have a mean of 51 and a standard deviation of 5.\n",
        "\n",
        "- Our expectation is that the statistical tests will detect that these two samples were drawn from different distributions.\n",
        "  - However, keep in mind that the small sample size of 100 observations per sample may introduce some noise into this decision.\n",
        "\n",
        "- Here's the complete code example for generating and summarizing the test data:\n",
        "  - Running this code will generate the data samples, calculate the mean and standard deviation for each sample, and confirm that they come from different distributions:"
      ],
      "metadata": {
        "id": "JBoUGDNqazPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import mean, std\n",
        "\n",
        "# Seed the random number generator\n",
        "seed(1)\n",
        "\n",
        "# Generate two sets of univariate observations\n",
        "data1 = 5 * randn(100) + 50\n",
        "data2 = 5 * randn(100) + 51\n",
        "\n",
        "# Summarize the data\n",
        "print('data1: mean=%.3f stdv=%.3f' % (mean(data1), std(data1)))\n",
        "print('data2: mean=%.3f stdv=%.3f' % (mean(data2), std(data2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GAqQeD9ayIX",
        "outputId": "f7c94a6c-fc6b-4c66-a98a-149d0d3d72b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data1: mean=50.303 stdv=4.426\n",
            "data2: mean=51.764 stdv=4.660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student’s t-Test\n",
        "\n",
        "- The Student’s t-test is a statistical hypothesis test used to compare two independent data samples that are known to have a Gaussian distribution.\n",
        "  - It's named after William Gosset, who used the pseudonym \"Student.\"\n",
        "\n",
        "- One of the most common uses of the t-test is the independent samples t-test.\n",
        "  - It comes in handy when you want to compare the means of two independent samples for a specific variable.\n",
        "\n",
        "- In this test, the null hypothesis (H0) assumes that the means of the two populations are equal.\n",
        "  - If we reject this hypothesis, it means there's enough evidence to conclude that the means of the populations are different, and consequently, the distributions are not equal.\n",
        "\n",
        "- Here's how to interpret the results of the t-test:\n",
        "\n",
        "  - Fail to Reject H0: Indicates no significant difference between the sample means.\n",
        "  - Reject H0: Suggests a significant difference between the sample means.\n",
        "\n",
        "- You can perform the Student’s t-test in Python using the `ttest_ind()` function from SciPy.\n",
        "  - This function takes two data samples as arguments and returns the calculated statistic and p-value.\n",
        "  - The test assumes that both samples have the same variance. If they don't, you can use a corrected version of the test by setting the `equal_var` parameter to False.\n",
        "\n",
        "- Here's a code example demonstrating the Student’s t-test on a test dataset, with the expectation that the test will reveal a difference in distribution between the two independent samples:\n",
        "\n",
        "  - Running this code will calculate the Student’s t-test on the data samples and print the statistic and p-value.\n",
        "  - In the example, the interpretation reveals that the sample means are different, with a significance level of at least 5%:\n"
      ],
      "metadata": {
        "id": "zt3JyKVBbDXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Student's t-test\n",
        "from numpy.random import seed, randn\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Seed the random number generator\n",
        "seed(1)\n",
        "\n",
        "# Generate two independent samples\n",
        "data1 = 5 * randn(100) + 50\n",
        "data2 = 5 * randn(100) + 51\n",
        "\n",
        "# Compare the samples\n",
        "stat, p = ttest_ind(data1, data2)\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Different distributions (reject H0)')"
      ],
      "metadata": {
        "id": "Pi9VaqZXbQYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paired Student’s t-Test\n",
        "\n",
        "- Sometimes, we need to compare the means of two data samples that are somehow related.\n",
        "  - For instance, these data samples may represent two evaluations of the same object, making them dependent or \"paired\" samples.\n",
        "  - When dealing with such paired samples, we cannot use the standard Student’s t-test. Instead, we turn to a modified version of the test designed for dependent data, called the paired Student’s t-test.\n",
        "\n",
        "- A dependent samples t-test is used to compare two means on a single dependent variable.\n",
        "  - Unlike the standard independent samples test, a dependent samples t-test is specifically for comparing the means of a single sample or two matched/paired samples.\n",
        "\n",
        "- In this test, we simplify the assumption that there is variation between observations, typically made in pairs before and after a treatment on the same subjects.\n",
        "  - The null hypothesis (H0) of the test assumes there is no difference in means between the samples.\n",
        "  - Rejecting this null hypothesis indicates that there is sufficient evidence that the sample means are different.\n",
        "\n",
        "- Here's how to interpret the results:\n",
        "\n",
        "  - Fail to Reject H0: Indicates that the paired sample distributions are equal.\n",
        "  - Reject H0: Suggests that the paired sample distributions are not equal.\n",
        "\n",
        "- You can perform the paired Student’s t-test in Python using the `ttest_rel()` function from SciPy.\n",
        "  - This function takes two data samples as arguments and returns the calculated statistic and p-value.\n",
        "  - Below is an example of the paired Student’s t-test on a test dataset. Although the samples are independent for this demonstration, we'll pretend they are paired to calculate the statistic:\n",
        "    - Running this code will calculate the paired Student’s t-test on the data samples and print the statistic and p-value.\n",
        "    - In this example, the interpretation suggests that the samples have different means and, therefore, different distributions:\n"
      ],
      "metadata": {
        "id": "uWg7EMPrbTp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paired Student's t-test\n",
        "from numpy.random import seed, randn\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Seed the random number generator\n",
        "seed(1)\n",
        "\n",
        "# Generate two independent samples\n",
        "data1 = 5 * randn(100) + 50\n",
        "data2 = 5 * randn(100) + 51\n",
        "\n",
        "# Compare the samples\n",
        "stat, p = ttest_rel(data1, data2)\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Different distributions (reject H0)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFo_LLcGbgrO",
        "outputId": "6c4282d7-9d94-4d23-8e9d-b5cf1ebe1368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=-2.372, p=0.020\n",
            "Different distributions (reject H0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Variance Test (ANOVA)\n",
        "\n",
        "- In some cases, we may have multiple independent data samples and want to determine whether they all have the same distribution.\n",
        "  - Rather than performing the Student’s t-test pairwise on each combination of data samples, we can use the analysis of variance test, known as ANOVA.\n",
        "  - ANOVA is a statistical test that assumes the means across two or more groups are equal.\n",
        "  - If the evidence suggests otherwise, the null hypothesis is rejected, indicating that at least one data sample has a different distribution.\n",
        "\n",
        "- Here's how to interpret the results:\n",
        "\n",
        "  - Fail to Reject H0: Indicates that all sample distributions are equal.\n",
        "  - Reject H0: Suggests that one or more sample distributions are not equal.\n",
        "\n",
        "- Importantly, ANOVA can only tell us whether all samples are the same or not; it cannot quantify which samples differ or by how much.\n",
        "\n",
        "- The purpose of a one-way analysis of variance (one-way ANOVA) is to compare the means of two or more groups (the independent variable) on one dependent variable to see if the group means are significantly different from each other.\n",
        "\n",
        "- The ANOVA test requires that the data samples follow a Gaussian distribution, that the samples are independent, and that all data samples have the same standard deviation.\n",
        "\n",
        "- You can perform the ANOVA test in Python using the `f_oneway()` function from SciPy. This function takes two or more data samples as arguments and returns the test statistic and f-value.\n",
        "\n",
        "  - Running this code calculates and prints the test statistic and the p-value.\n",
        "  - In this example, the interpretation indicates that the null hypothesis is rejected, suggesting that one or more sample means are different:\n"
      ],
      "metadata": {
        "id": "HVKGBEDBbhez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of Variance Test (ANOVA)\n",
        "from numpy.random import seed, randn\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Seed the random number generator\n",
        "seed(1)\n",
        "\n",
        "# Generate three independent samples\n",
        "data1 = 5 * randn(100) + 50\n",
        "data2 = 5 * randn(100) + 50\n",
        "data3 = 5 * randn(100) + 52\n",
        "\n",
        "# Compare the samples\n",
        "stat, p = f_oneway(data1, data2, data3)\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print('Same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Different distributions (reject H0)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNscnXP3bvcB",
        "outputId": "09f8d4f2-69df-4bef-e1bc-5f38cfb1c702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=3.655, p=0.027\n",
            "Different distributions (reject H0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Repeated Measures ANOVA Test\n",
        "\n",
        "- In some cases, we may have multiple data samples that are related or dependent.\n",
        "  - For example, we might collect measurements on the same subject at different time periods.\n",
        "  - In such scenarios, the data samples are no longer independent; instead, they become paired or dependent samples.\n",
        "  - Instead of repeatedly performing pairwise Student’s t-tests, we can use a single test to determine if all the samples have the same mean. This test is called the repeated measures ANOVA test.\n",
        "\n",
        "- The default assumption or null hypothesis of this test is that all paired samples have the same mean, implying they share the same distribution.\n",
        "  - If the data suggests otherwise, we reject the null hypothesis, indicating that one or more paired samples have different means.\n",
        "\n",
        "- Here's how to interpret the results:\n",
        "\n",
        "  - Fail to Reject H0: Indicates that all paired sample distributions are equal.\n",
        "  - Reject H0: Suggests that one or more paired sample distributions are not equal.\n",
        "\n",
        "- Repeated-measures ANOVA offers several advantages over paired t-tests. With this test, we can examine differences on a dependent variable measured at more than two time points, whereas an independent t-test only allows comparisons between two time points.\n",
        "\n",
        "- Unfortunately, as of the time of writing, SciPy does not include a version of the repeated measures ANOVA test.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "x9Z9U1-CbA-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Reading\n",
        "\n",
        "### Books\n",
        "- \"Statistics in Plain English, Third Edition\" (2010)\n",
        "\n",
        "### API Documentation\n",
        "- [scipy.stats.ttest_ind API](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)\n",
        "- [scipy.stats.ttest_rel API](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html)\n",
        "- [scipy.stats.f_oneway API](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html)\n",
        "\n",
        "### Articles\n",
        "- [Statistical Significance on Wikipedia](https://en.wikipedia.org/wiki/Statistical_significance)\n",
        "- [Student’s t-test on Wikipedia](https://en.wikipedia.org/wiki/Student%27s_t-test)\n",
        "- [Paired Difference Test on Wikipedia](https://en.wikipedia.org/wiki/Paired_difference_test)\n",
        "- [Analysis of Variance on Wikipedia](https://en.wikipedia.org/wiki/Analysis_of_variance)\n",
        "- [Repeated Measures Design on Wikipedia](https://en.wikipedia.org/wiki/Repeated_measures_design)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "b66_cAisbwDW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UWkvi3MKb93Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}