{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical Hypothesis Testing\n",
        "\n",
        "- Data can tell us meaningful stories, but to do that, we need to interpret it. We make interpretations by making educated guesses, which we call hypotheses. We then use statistical methods to check if these guesses are true or not. These tests are known as statistical hypothesis tests.\n",
        "\n",
        "- Why are they important? Well, they help us answer questions about data. For example, if we want to know if two sets of results are different or if our data follows a certain pattern, we turn to these tests.\n",
        "\n",
        "In this tutorial, we'll dive into statistical hypothesis testing. By the end, you'll understand:\n",
        "\n",
        "1. Why we need statistical hypothesis tests.\n",
        "2. What p-values and critical values mean in the context of interpreting these tests.\n",
        "3. And, why we should be aware that even if a test suggests something, there can still be errors.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "luvRIqghw7fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Statistical Hypothesis Testing\n",
        "\n",
        "Data alone doesn't reveal much. It's the meaning we derive from data that matters. In the case of statistics, when we want to explore data and make sense of it, we turn to statistical methods.\n",
        "- These methods give us a degree of confidence in the answers they provide, and they're known as statistical hypothesis tests or significance tests.\n",
        "\n",
        "- Think of a hypothesis as an educated guess, just like in science.\n",
        "\n",
        "- In statistics, we use hypothesis tests to calculate some value based on an assumption. This result helps us determine if the assumption is valid or if it's been proven wrong. In machine learning, two common examples of this are:\n",
        "\n",
        "  1. Testing if data follows a normal distribution.\n",
        "\n",
        "  2. Testing if two sets of data come from the same underlying population.\n",
        "\n",
        "- The assumption made in a statistical test is called the null hypothesis, often represented as H0. It's like the default assumption, the status quo, assuming that nothing has changed.\n",
        "  - When a test suggests that this assumption doesn't hold, we call it the first hypothesis, H1.\n",
        "\n",
        "  - H1 represents the idea that something has changed, but it doesn't specify what that change is.\n",
        "\n",
        "- In a nutshell:\n",
        "  - Hypothesis 0 (H0): The test's assumption is not rejected.\n",
        "  - Hypothesis 1 (H1): The test's assumption is rejected at a certain level of significance.\n",
        "\n",
        "- But before we make the call to accept or reject the null hypothesis, we need to interpret the test's result.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "I_AUlgGvxR3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpreting Statistical Test Results\n",
        "\n",
        "When we perform a statistical hypothesis test, the results require interpretation.\n",
        "- This step can be confusing, whether you're a beginner or an experienced practitioner.\n",
        "\n",
        "- There are two common ways results from a statistical hypothesis test can manifest, and they require different interpretations.\n",
        "\n",
        "- These two forms are the p-value and critical values."
      ],
      "metadata": {
        "id": "bhoySAFtxkUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpreting the p-value:\n",
        "\n",
        "- When we're analyzing data, we use something called a p-value to determine if our findings are statistically significant.\n",
        "  - For instance, let's say we compare two sets of data using a Student's t-test and discover that it's unlikely they have the same average.\n",
        "  - In such cases, we decide to reject the idea that both sets have the same average, but we do this at a pre-determined level of certainty or confidence.\n",
        "\n",
        "- The result of a statistical test will yield a number known as the p-value.\n",
        "  - This number allows us to gauge and put a measure on the test's outcome, which, in turn, helps us decide whether we should reject or keep the initial assumption (null hypothesis).\n",
        "\n",
        "- To do this, we compare the p-value to a pre-established value known as the significance level.\n",
        "  - Often, the significance level is denoted by the Greek letter alpha (α), and a typical choice for alpha is 5% or 0.05.\n",
        "  - Smaller alpha values, such as 1% or 0.1%, indicate a more rigorous criterion for a significant result.\n",
        "\n",
        "- So, here's how to interpret it:\n",
        "\n",
        "  - If p-value is less than or equal to alpha (p-value ≤ alpha), it means the result is statistically significant. We reject the initial assumption (null hypothesis) in favor of an alternative hypothesis (H1). In simpler terms, we've found a significant change or difference.\n",
        "\n",
        "  - If p-value is greater than alpha (p-value > alpha), it suggests the result is not statistically significant. In such cases, we fail to reject the initial assumption (null hypothesis or H0), meaning we don't have enough evidence to claim a significant change or difference.\n",
        "\n",
        "  - You can also think of the significance level as a measure of confidence. You can calculate the confidence level (given the sample data) by subtracting the significance level from 1: `confidence level = 1 - significance level`\n",
        "\n",
        "    - A higher confidence level indicates a greater degree of certainty in the results.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ji1rlhP0xwYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding \"Reject\" vs. \"Failure to Reject\"\n",
        "\n",
        "- The p-value operates on probability.\n",
        "  - This means that when we analyze the results of a statistical test, we don't determine what's true or false with certainty, but rather what's `likely`.\n",
        "\n",
        "  - When we \"reject\" the null hypothesis, it means we have enough statistical evidence to say the null hypothesis is `unlikely` to be true based on our data.\n",
        "\n",
        "  - On the other hand, when we \"fail to reject\" the null hypothesis, it means we don't have enough statistical evidence to declare it `unlikely`.\n",
        "\n",
        "- This concept can be thought of as a choice between \"rejecting\" or \"accepting\" the null hypothesis.\n",
        "  - However, it's important to recognize that saying we \"accept\" the null hypothesis might suggest it's true, which isn't entirely accurate.\n",
        "  \n",
        "  - To be more precise, we say we \"fail to reject\" the null hypothesis, meaning there's insufficient statistical evidence to discard it.\n",
        "\n",
        "-  For newcomers, the distinction between \"reject\" and \"fail to reject\" can be a bit confusing initially.\n",
        "  - You can simplify it in your mind as \"reject\" vs. \"accept,\" but always remember that the result is probabilistic.\n",
        "\n",
        "  - Even if you \"accept\" the null hypothesis, there remains a small probability that it could be incorrect.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "NIjdtqt9zSxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common P-Value Misinterpretations\n",
        "\n",
        "**1. True or False Null Hypothesis**\n",
        "\n",
        "- The p-value's interpretation does not determine whether the null hypothesis is true or false. Instead, it signifies our decision to either reject or fail to reject the null hypothesis, based on empirical evidence and the chosen statistical test.\n",
        "\n",
        "- We can only make probabilistic claims, not absolute true/false declarations about the result.\n",
        "\n",
        "  ---\n",
        "\n",
        "**2. P-Value as Probability**\n",
        "\n",
        "- A common misconception is that the p-value represents the probability of the null hypothesis being true or false given the data. In probability terms, this would be expressed as:\n",
        "\n",
        "  - $ P(hypothesis|data) $\n",
        "  - This understanding is incorrect.\n",
        "\n",
        "- Rather, the p-value can be thought of as the probability of observing the data under the specific assumption embedded in the statistical test. In probability notation, it would be:\n",
        "\n",
        "  - $ P(data|hypothesis) $\n",
        "\n",
        "- This allows us to assess whether the data aligns with the hypothesis, not the reverse. The p-value measures how likely the observed data would be if the null hypothesis were true.\n",
        "\n",
        "  ---\n",
        "\n",
        "\n",
        "**3. Post-Hoc Tuning**\n",
        "\n",
        "- The p-value should not be used to justify resampling your data or modifying your sample until you achieve a desired result.\n",
        "\n",
        "- Nor should you choose your p-value after conducting the test.\n",
        "\n",
        "- These practices are known as p-hacking or hill climbing and can render your results unreliable and non-representative.\n",
        "\n",
        "  - In scientific terms, they are considered unethical at best and fraudulent at worst.\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "yR_XG-CWzrUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Critical Values\n",
        "\n",
        "- In some cases, statistical tests don't provide a p-value but offer a test statistic instead. To make sense of these test statistics, we use critical values.\n",
        "  - Critical values are specific values derived from the test statistic's distribution.\n",
        "\n",
        "  - They mark the point at which a result becomes significant and leads to the rejection of the null hypothesis.\n",
        "\n",
        "  - **Test Statistic < Critical Value:** This suggests a non-significant result, and you should refrain from rejecting the null hypothesis (H0).\n",
        "\n",
        "  - **Test Statistic ≥ Critical Value:** In this scenario, the result is deemed significant, and you should reject the null hypothesis (H1).\n",
        "\n",
        "- Utilizing critical values requires an understanding of the distribution of the test statistic and the methodology for obtaining these critical values. This is typically demonstrated in standard distributions, as explained in Chapter 11.\n",
        "  - The p-value is often calculated based on the critical value.\n",
        "\n",
        "- The interpretation of these results is akin to that of p-values, as they involve selecting a significance level.\n",
        "\n",
        "  - It's a probabilistic decision regarding whether to accept or reject the core assumption of the test based on the available data.\n",
        "\n",
        "  - Results are conveyed in a similar fashion to p-values, indicating either a significance level or a confidence level.\n",
        "\n",
        "  - For example, in a normality test, if the test statistic is compared to the critical value at the 5% significance level, the results could be described as:\n",
        "    - The test suggests that the data sample is normal, and we fail to reject the null hypothesis at a 5% significance level.\n",
        "\n",
        "    - Or, the test indicates that the data is normal, and we fail to reject the null hypothesis at a 95% confidence level.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ncC0YKJjENky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Errors in Statistical Tests\n",
        "\n",
        "- The interpretation of a statistical hypothesis test is based on probabilities, meaning that the test results can sometimes be misleading. Here, we discuss two types of errors that can occur in statistical testing and their specific names.\n",
        "\n",
        "- **Type I Error (False Positive):** This error happens when a true null hypothesis is incorrectly rejected.\n",
        "  - In other words, we mistakenly conclude that there is an effect or difference when there isn't one. It's like a false alarm.\n",
        "\n",
        "- **Type II Error (False Negative):** This error occurs when we fail to reject a false null hypothesis.\n",
        "  - We incorrectly accept the null hypothesis or the assumption of the statistical test, even though there may be an effect or difference. It's like missing a real signal because of noise.\n",
        "\n",
        "- Every statistical hypothesis test has the potential to make one of these two errors.\n",
        "  - False findings or false discoveries are not just possible; they are likely.\n",
        "  - Ideally, we aim to select a significance level that minimizes the chances of these errors, often using a very small significance level (e.g., 0.05 or 0.01), although in some fields like physics, more stringent levels like 3 × 10⁻⁷ (0.0000003), known as \"5-sigma,\" are employed.\n",
        "  - This stringent threshold indicates that the result occurred by chance in only 1 in 3.5 million independent repetitions of the experiments.\n",
        "\n",
        "- However, it's important to note that these errors are inherent in statistical testing and should be considered when presenting and interpreting results.\n",
        "  - Independent verification of findings is crucial to minimize the impact of these errors and enhance the reliability of conclusions.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-jVsEXMRE1KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Degrees of Freedom in Statistics\n",
        "\n",
        "- When performing statistical calculations, it's essential to account for the size of your data sample. This is achieved through a concept known as \"degrees of freedom.\"\n",
        "  - Degrees of freedom represent the number of independent pieces of information used to estimate a parameter or compute a statistic based on your data sample.\n",
        "\n",
        "- You might encounter degrees of freedom denoted as \"df\" or \"dof\" and represented in equations using the Greek lowercase letter nu (ν).\n",
        "  - The degrees of freedom are always equal to or less than the size of your sample, often denoted as \"n.\"\n",
        "\n",
        "- However, if your statistic calculation involves another statistic in an intermediate step, you must adjust the degrees of freedom by subtracting a value.\n",
        "\n",
        "  - For instance, when calculating the sample mean as an estimate of the population mean, you can use the sample size as the degrees of freedom: $ mean(x) = \\frac{1}{n} \\sum_{i=1}^{n} x_i $\n",
        "\n",
        "  - However, when calculating the sample variance as an estimate of the population variance, you need to correct the degrees of freedom because the sample mean is used in the calculation: $ variance(x) = \\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\text{mean}(x))^2 $\n",
        "\n",
        "  - This correction accounts for the additional uncertainty introduced by the use of the sample mean as an intermediate statistic.\n",
        "\n",
        "- Degrees of freedom are a parameter or correction that you'll encounter in various statistical hypothesis tests, where they play a crucial role in ensuring the accuracy of your statistical inferences.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "qHaWFwT6E8Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further Reading\n",
        "\n",
        "### Articles\n",
        "\n",
        "1. [Statistical Hypothesis Testing on Wikipedia](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)\n",
        "2. [Statistical Significance on Wikipedia](https://en.wikipedia.org/wiki/Statistical_significance)\n",
        "3. [P-value on Wikipedia](https://en.wikipedia.org/wiki/P-value)\n",
        "4. [Critical Value on Wikipedia](https://en.wikipedia.org/wiki/Critical_value)\n",
        "5. [Type I and Type II Errors on Wikipedia](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)\n",
        "6. [Data Dredging on Wikipedia](https://en.wikipedia.org/wiki/Data_dredging)\n",
        "7. [Misunderstandings of P-values on Wikipedia](https://en.wikipedia.org/wiki/Misunderstandings_of_p-values)\n",
        "8. [What Does the 5 Sigma Mean?](http://www.physics.org/article-questions.asp?id=103)\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "xbF_psNjFMzU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OrQVriq7xRR8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}